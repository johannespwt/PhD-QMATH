\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{pdfpages}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{amsmath}
\DeclareMathOperator\arctanh{arctanh}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{centernot}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{braket}
\usepackage{pgfplots}
\usepackage{lastpage}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{cancel}
\usepackage[english]{babel} 

\usepackage[square,sort,comma,numbers]{natbib}
\usepackage[colorlinks=true,linkcolor=blue]{hyperref}

\usepackage{fancyhdr}
\newcommand{\euler}[1]{\text{e}^{#1}}
\newcommand{\Real}{\text{Re}}
\newcommand{\Imag}{\text{Im}}
\newcommand{\supp}{\text{supp}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\Span}[1]{\text{span}\left(#1\right)}
\newcommand{\dom}[1]{\mathscr D\left(#1\right)}
\newcommand{\Ran}[1]{\text{Ran}\left(#1\right)}
\newcommand{\conv}[1]{\text{co}\left\{#1\right\}}
\newcommand{\Ext}[1]{\text{Ext}\left\{#1\right\}}
\newcommand{\vin}{\rotatebox[origin=c]{-90}{$\in$}}
\newcommand{\interior}[1]{%
	{\kern0pt#1}^{\mathrm{o}}%
}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\ie}{\emph{i.e.} }
\newcommand{\eg}{\emph{e.g.} }
\newcommand{\dd}{\partial }
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\w}{\mathsf{w}}

\newcommand{\Gliminf}{\Gamma\text{-}\liminf}
\newcommand{\Glimsup}{\Gamma\text{-}\limsup}
\newcommand{\Glim}{\Gamma\text{-}\lim}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\numberwithin{equation}{section}
\linespread{1.3}

\pagestyle{fancy}
\fancyhf{}
\rhead{CoCo - Assignment 1}
\lhead{}
\rfoot{\thepage}
\lfoot{Dated: \today}
\author{Johannes Agerskov, Mads Friis Frand-Madsen, and Sifan Huang}
\date{Dated: \today}
\title{CoCo - Assignment 2}
\begin{document}
	
	\maketitle
	\section*{2.6}
	Give CFGs that generate the following languages:
	\subsection*{b)}
	$ L=\{a,b\}^\ast\setminus\{a^nb^n\ \vert n\geq0\}=\{a^nb^n\ \vert n\geq0\}^{\complement} $.\\
	Consider the following CFG:\begin{equation}
	\begin{aligned}
	S&\to X \ \vert\ Y\ \vert\ Z,\\
	Z&\to aZ\ \vert\ Za\ \vert\ Zb \ \vert\ bZ \ \vert\ ba,\\
	X&\to aX\ \vert\ aXb\ \vert\ a,\\
	Y&\to Yb \ \vert\ aYb \ \vert\ b
	\end{aligned}
	\end{equation}
	Here we see that the tree of all derivation contain one branch for each of the variables $ X,\ Y $ and $ Z $. The $ X $ branch generates all strings of the form $ a^ib^j $ for $ i>j $. The $ Y $ branch derives all string of the form $ a^ib^j $ for $ i<j $. Finally the $ Z $ branch generate all string that contain the substring $ ba $, i.e. which is not of the form $ a^ib^j $ for any $ i,j\in\N $. Thus we see that this context free grammar generates all string expect those of the form $ a^nb^n $, $ n\geq0 $.
	\subsection*{d)}
	$ L=\{x_1\#x_2\#...\#x_k\ \vert\ k\geq1, \text{each $ x_i\in \{a,b\}^\ast $, and for some $ i $ and $ j $, $ x_i=x_j^\mathcal{R} $}\} $.\\
	Consider the following CFG:\begin{equation}
	\begin{aligned}
	S&\to XYZ,\\
	Y&\to aYa \ \vert\ bYb\ \vert\ \#T\#\ \vert\ \varepsilon\\
	X&\to T\#\ \vert\ \varepsilon,\\
	Z&\to \#T\ \vert\ \varepsilon,\\
	T&\to aT\ \vert\ bT\ \vert\ T\#T\ \vert\ \varepsilon.
	\end{aligned}
	\end{equation}
	Notice that $ Y $ generates a palindromic string of even length (could also be $ \varepsilon $) that then might be split in the middle by a $ \#T\# $ ($ \varepsilon\#T\#\varepsilon $ in the case of empty string). Now $ T $ can generate any number of strings in $ \{a,b\}^\ast $ separated by any number of $ \# $s. Thus any string generated by this grammar will be $ x_1\#x_2\#...\#x_i\#...\#x_j\#...\#x_k $ for some $ k\geq1 $ and for some $ i,j\geq1 $ where $ \abs{x_i}=\abs{x_j} $ and $ x_ix_j $ is a palindromic string. Thus since $ x_ix_j=(x_ix_j)^\mathcal{R}=x_j^\mathcal{R}x_i^\mathcal{R} $ we have $ x_i=x_j^\mathcal{R} $. On the contrary is it obvious that we can generate every string in $ L $ by this CFG. Thus the CFG generates $ L $.
	
	\section*{2.14}
	Convert the following CFG into Chomsky normal form.
	\begin{equation*}
	\begin{aligned}
	A&\to BAB \ \vert\ B \ \vert\ \varepsilon,\\
	B&\to 00\ \vert\ \varepsilon.
	\end{aligned}
	\end{equation*}
	We start by adding a new start variable and removing all $ \epsilon $-rules\begin{equation*}
	\begin{aligned}
	S&\to A\ \vert\ \varepsilon,\\
	A&\to BAB\ \vert\ BB \ \vert\ AB \ \vert\ BA \ \vert\ \underbrace{A}_{redundant} \ \vert\ B \ \vert\ \cancel{\varepsilon},\\
	B&\to 00 \ \vert\ \cancel{\varepsilon}.
	\end{aligned}
	\end{equation*}
	We then remove all unit rules 
	\begin{equation*}
	\begin{aligned}
	S&\to BAB\ \vert\ BB \ \vert\ AB \ \vert\ BA \ \vert\ 00\ \vert\ \varepsilon,\\
	A&\to BAB\ \vert\ BB \ \vert\ AB \ \vert\ BA \ \vert\ 00,\\
	B&\to 00.
	\end{aligned}
	\end{equation*}
	Finally we patch up the grammar to get it to Chomsky normal form
	\begin{equation*}
	\begin{aligned}
	S&\to T_1B\ \vert\ BB \ \vert\ AB \ \vert\ BA \ \vert\ T_2T_2\ \vert\ \varepsilon,\\
	A&\to T_1B \ \vert\ BB\ \vert \ AB \ \vert\ BA \ \vert\ T_2T_2,\\
	B&\to T_2T_2,\\
	T_1&\to BA,\\
	T_2&\to 0
	\end{aligned}
	\end{equation*}
	The CFG is then written in Chomsky normal form.	
	
	\section*{2.42}
	Use the pumping lemma for CFLs to show that the following languages are \emph{not} context free.
	\subsection*{a)}
	Let $ L=\{0^n1^n0^n1^n\ \vert\ n\geq0 \} $,. We show that $ L $ is not context free.
	\begin{proof}
		Assume that $ L $ is context free and let $ p $ be its pumping length as given by the pumping lemma. Consider then the string $ w=0^p1^p0^p1^p\in L $. According to the pumping lemma, we can split $ w=uvxyz $ where $ \abs{vxy}\leq p $ and $ \abs{vy}>0 $. Now if $ vxy=0^m $ for some $ 0<m\leq p $, then $ uv^2xy^2z\notin L $ since it contains more $ 0 $s than $ 1 $s. If $ vxy=1^m $ for some $ 0<m\leq p $, then $ uv^2xy^2z\notin L $ since it contains more $ 1 $s than $ 0 $s. If $ vxy=0^n1^m $ for some $ 2\leq n+m\leq p $ then $ vxy $ belong to one of the halfs of $ w $ and thus $ uv^2xy^2z\notin L $ since it does not contain an equal amounts of $ 1 $s and $ 0 $s across the middle. If $ vxy=1^m0^n $ for some $ 2\leq n+m\leq p $ then $ uv^2xy^2z=0^p1^k0^{k'}1^p\notin L $ since $ k>p$ \emph{or} $k'>p $ ($ v $ contains at least one $ 0 $ \emph{or} $ y $ contains at least one $ 1 $). Thus a contradiction with the pumping lemma is unavoidable, and we conclude that $ L$ is not context free
	\end{proof}
	\subsection*{d)}
	Let $ L=\{t_1\#t_2\#...\#t_k\ \vert\ k\geq2, \text{each }t_i\in\{a,b\}^\ast,\ t_i=t_j\text{ for some }i,j\} $. We show that $ L $ is not context free.
	\begin{proof}
		Assume that $ L $ is context free and let $ p $ be its pumping length as given by the pumping lemma. Consider then the string $ w=a^pb^p\#a^pb^p\in L $. Split the string $ w=uvxyz $ according to the pumping lemma. Now either $ vxy=b^j\#a^i $ for some $ i+j\leq p-1 $ \emph{or} $ vxy=a^ib^j $ for some $ i+j\leq p $. In the second case $ vy=a^mb^n $ for some $ 0<n+m\leq p $ and thus $ uv^0xy^0z=a^{p-m}b^{p-n}\#a^pb^p\notin L $ \emph{or} $ uv^0xy^0z=a^pb^p\#a^{p-m}b^{p-n}\notin L $. If $ vxy=b^j\#a^i $ then if $ \#\in v $ or $ \#\in y $ we have $ \#\notin uv^0xy^0z $ and thus $ uv^0xy^0z\notin L $ by the $ k\geq2 $ condition in the definition of $ L $. If $ \#\in X $ then $ v=b^l $ and $ y=a^{l'} $ for $ 0<l+l'\leq p $ and thus $ uv^2xy^2z=a^pb^{p-l}\#a^{p-l'}b^p\notin L $. Thus a contradiction is unavoidable, and we conclude that $ L $ is not context free.
	\end{proof}
	
	\section*{2.54}
	Let $ Y=\{w\ \vert\ w=t_1\#t_2\#...\#t_k, \text{for }k\geq0,\ t_i\in 1^\ast\text{ and } t_i\neq t_j\text{ for }i\neq j \} $. We prove that $ Y $ is not a context free language. \begin{proof}
		Assume for contradiction that $ Y $ is a CFL with pumping length, as given by the pumping lemma, $ p $. Let $ w=1^p\#1^{p+1}\#...\#1^{3p} \in Y$. By the pumping lemma it is known that we can split $ w=uvxyz $ where $ \abs{vxy}\leq p $ and $ \abs{vy}>0 $. If $ vxy $ contains a $ \# $ symbol (notice that it can contain at most one $ \# $), then if $ \#\in v $ we have $ v=1^m\#1^n $ for some $ n,m\leq p $ and then $ v^3=1^m\#\underbrace{1^{n+m}}_{t_i}\#\underbrace{1^{n+m}}_{t_{i+1}}\#1^n $, which contains two sections $ t_i=t_{i+1} $. Thus, any string containing $ v^3 $ is not in $ Y $ which contradicts the pumping lemma. The same applies for $ y $. Therefore we must have $ \#\in x $. But then $ v=1^m $ and $ y=1^n $ for some $ 0<n+m\leq p-1 $ (since $ x $ contains at least a $ \# $). Thus \begin{equation*}
		\begin{aligned}
		uv^0xy^0z=1^p\#...\#1^{p+k-1}\#1^{p+k-m}\#1^{p+k+1-n}\#...\#1^{3p}\\
		uv^2xy^2z=1^p\#...\#1^{p+k-1}\#1^{p+k+m}\#1^{p+k+1+n}\#...\#1^{3p}
		\end{aligned}
		\end{equation*}
		Now we clearly have $ p+k-m\geq p $ \emph{or} $ p+k+1+n\leq2p $, since $ m+n+1\leq p $. Therefore, we conclude that either, if $ p+k-m\geq p $, we have $  uv^0xy^0z\notin Y $ since the substring $ \#1^{p+k-m}\# $ occurs twice, \emph{or}, if $ p+k+1+n\leq2p $, we have $ uv^2xy^2z\notin Y $ since the substring $ \#1^{p+k+1+n} $ occurs twice. Thus we see that $ \#\in vxy $ leads to a contradiction with the pumping lemma.\\
		On the other hand if $ vxy=1^m $ for some $ 0<m\leq p $ then $ vy=1^n $ for some $ 0<n\leq m $. Thereby, either $ uv^0xy^0z\notin Y $ or $ uv^2xy^2z\notin Y $ since at least one of these contain two sections that are equal. Too see this, notice that $ uv^0xy^0z=1^p\#...\#1^{p+k-1}\#1^{p+k-n}\#1^{p+k+1}\#...\#1^{3p} $ and $ uv^2xy^2z=1^p\#...\#1^{p+k-1}\#1^{p+k+n}\#1^{p+k+1}\#...\#1^{3p}  $ and since $ n\leq p $ we clearly have $ p+k+n\leq3p $ or $ p+k-n\geq p $.
		
		Thus a contradiction is unavoidable and we conclude that $ Y $ is not context free.
	\end{proof}
	
	\section*{3.16}
	Show that the collection of decidable languages is closed under the following operations.
	\subsection*{b) Concatenation}
	\begin{proof}
		Given two deciable languages, $L_1$ and $L_2$, let $M_1$ and $M_2$ be Turing Machinces (TMs) that decides them. We construct a TM, $M$, that decides the concatenation, $L_1L_2$, of the two languages. For any string, $w$, let $w|_{k}$ denote the first $k$ entries in $w$ and $w|^{k}$ denote rest of $w$, such that $w=w|_{k}w|^{k}$ for any $0\leq k\leq|w|$. Here we define $w|_0=w|^{\abs{w}}=\varepsilon$. We define $M$ by the following algorithm: Given an input string $w$\begin{enumerate}
			\item Set $k=0$.
			\item Set $k' $ such that $ k'=k $.
			\item Run $M_1$ on $w_k$.
			\item If $M_1$ accepts, run $M_2$ on $w|^{k}$. If $M_1$ rejects $w|_k$ and $k<\abs{w}$, set $k $ such that $k=k'+1$ and return to 2. If $M_1$ rejects $w|_k$ and $k=\abs{w}$, $M$ \emph{rejects}.
			\item If $M_2$ accepts $w|^{k}$, $M$ \emph{accepts}. If $M_2$ rejects $w|^{k}$ and $k<\abs{w}$, set $k $ such that $k=k'+1$ and return to 2. If $M_2$ rejects $w|^k$ and $k=\abs{w}$, $M$ \emph{rejects}.
		\end{enumerate}
		Clearly, $M$ is a decider, and it accepts a string $w$ if and only if $w=xy$ for $x\in L_1$ and $y\in L_2$.\\
			\\
			Given decidable language $L_1$ and $ L_2 $, let $M_1$ and $ M_2 $ be TMs that decides them. We construct an NTM, $M$ that decides $L_1L_2$. We use that a language is decidable if and only if some NTM decides it (Corollary 3.19). We define a NTM, $M$, to non-deterministically on the tape, split the input string in all possible ways. This can be done by letting the machine either put a $ \# $ between its current head location and the one to right \emph{or} leave it be. If it put down a $ \# $, it continues with the rest of the computation, and if it did not, it simply stays in the same state and moves right. Repeating all the way down the string until it meets a $ \sqcup $, at which case it just rejects. the Turing machine then runs $M_1$ on the first component \ie everything before $ \# $ and $ M_2 $ on the second component \ie everything after $ \# $. If $M_1$ moves its head right to a $\#$ we simply move the entire tape to the right of an including that $\#$ one slot right and produce a blank slot to the left of that $ \# $ and if $ M_2 $ moves left onto a $ \# $ it simply return to the slot to the right of the $ \# $ simulating the beginning of the tape. $M$ then \emph{accepts} if for \emph{one of all} the non-deterministic branches both $M_1$ \emph{and} $M_2$ accept. Clearly $ M $ is a decider since each non-deterministic branch will be decided.
	\end{proof}
	\subsection*{c) Kleene star}
	\begin{proof}
			Given a decidable language $L$, let $M_1$ be a TM that decides $L$. We construct a TM, $M$ that decides $L^\ast$. We define first an auxiliary TM  $M'=M$. We then define $M$ (and $M'$) by the following algorithm: Given an input string\begin{enumerate}
				\item If $w=\varepsilon$, $ M $ \emph{accepts}.
				\item Set $k=1$.
				\item Set $k' $ such that $ k'=k $.
				\item Run $M_1$ on $w|_k$.
				\item If $M_1$ accepts $ w|_k $, $ M $ marks the part of the string $w|_k$ and run $M$ with the unmarked part of $w$, $w|^k$, as input string, if this $M$ rejects $w|^k$ and $k<\abs{w}$, set $k=k'+1$ and return to 3. If $M$ rejects $w|^k$ and $k=\abs{w}$, $ M $ \emph{rejects}. If $M_1$ rejects $w|_k$ and $k<\abs{w}$, set $k $ such that $k=k'+1$ and return to 3. If $M_1$ rejects $w|_k$ and $k=\abs{w}$, $M$ \emph{rejects}.
			\end{enumerate}
			Notice that this definition of $M$ refers to itself, however, we are guaranteed that this recursion is finite by the observation that every recursive step shortens the remaining string by at least one, and we we end up with the empty string $M$ accepts if it has not rejected before that point. Thus it is clear that $ M $ is a decider.\\
			\\
		Given a decidable language $L$, let $M_1$ be a TM that decides $L$. We construct a TM, $M$ that decides $L^\ast$. We use that a language is decidable if and only if some NTM decides it (Corollary 3.19). We define a NTM, $M$, to non-deterministically on the tape, split the input string in all possible ordered splittings \ie all possible ways of splitting the string $w$ in $w_1\#w_2\#...\#w_n$ such that $w_1w_2...w_n=w$, where $n\in\N$. This can be done by letting the machine either put down a $ \# $ to right of its current head location and then move two right such it is located to the left of $ \# $, \emph{or} simply move one right. It then repeats this non-deterministic process. It stops a non-deterministic branch and continues the calculation, as described below, when it meets a $ \sqcup $. After having stopped a branch.  It then runs $M_1$ on each split component,\ie substring $ w_i $ that is squeezed between two $\#$-symbols. If $M_1$ moves its head right to a $\#$ we simply move the tape to the right of an including that $\#$ one slot right and produce a blank slot on the left of that $ \# $. $M$ then accepts if \emph{one of all} of the $M_1$s accept for \emph{some} ordered splitting of $w$. Clearly $ M $ is a decider since each non-deterministic branch will be decided.
	\end{proof}
	\subsection*{c) Complementation}
	\begin{proof}
		Let $L$ be a decidable language and $M_1$ a TM that decides it. We show that the complement of $L$ also is a decidable language. For an input string simply define the TM, $ M $ that runs $M_1$ on $w$. $M$ \emph{rejects} if $ M_1 $ accepts, and $M$ \emph{accepts} if $M_1$ rejects. Clearly $ M $ accepts an input string, $ w $, if and only if $ w\notin L $. Furthermore, $ M $ is a decider since $ M_1 $ is.
	\end{proof}
	\subsection*{d) Intersection}
	\begin{proof}
		Let $ L_1 $ and $ L_2 $ be decidable languages, and $ M_1 $ and $ M_2 $ be TMs that decides them. We then define the TM, $ M $ by: 
		Given an input string $w$, $ M $ runs $ M_1 $ on $ w $, if $ M_1 $ rejects, $ M $ \emph{rejects}. If $M_1$ accepts, $ M $ runs $ M_2 $ on $ w $. If $ M_2 $ rejects, $ M $ \emph{rejects}, if $ M_2 $ accepts, $ M $ \emph{accepts}. Clearly $ M $ accepts a string if and only if $ w\in L_1 $ and $ w\in L_2 $, \ie $ w\in L_1\cap L_2 $. Furthermore, $ M $ is a decider since $ M_1 $ and $ M_2 $ is.
	\end{proof}
	\section*{3.18}
	Consider the doubly infinite tape Turing machine. We show that this machine is equivalent to an ordinary TM. One direction is clear. Given the doubly infinite tape machine, we can simulate the ordinary TM by simply introducing a special symbol, $ \aleph $ to the left of the input string, and include the transition function $ \delta(q,\aleph)=(q,\aleph,R) $ for any state, $ q $. Such that moving to this tape location always sends you back to the left most input address.\\
	\\
	The other direction is more interesting. To Simulate the doubly infinite tape machine $ DM $, by an ordinary TM, $ M $, we include on the ordinary machine, a special character, $ \aleph $, and put it in the left most position of the tape. Now whenever the head of $ M $ is above $ \aleph $, $ M $ moves the entire tape except $ \aleph $ one slot to the right leaving a blank slot after $ \aleph $ which it then moves its head to. Thus the machine can now move infinitely to the left, by simply pushing the tape to the right. Clearly any doubly infinite tape machine can be simulated in this way. If $ DM $ accepts an input string, $ M $ with the same transition functions and states including this extra tape letter and transition functions for this letter, will perfom the same computations and thus accept the string. On the contrary, if $ DM $ does not accept $ w $ then $ M $ will not accept, since if can only enter the accept state if $ DM $ does so.
	
\end{document}